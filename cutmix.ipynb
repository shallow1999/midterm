{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检查GPU是否可用： cuda\n",
      "Sun May  8 20:10:41 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090    Off  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 32%   40C    P8    40W / 350W |   6437MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 3090    Off  | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 84%   68C    P2   326W / 350W |  15615MiB / 24268MiB |     87%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # 使用指定GPU\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder, CIFAR100\n",
    "from torchtoolbox.tools import summary\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "print('检查GPU是否可用：',device)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从kaggle下载数据集CIFAR-100数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./2021-ai-training\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "\n",
    "od.download('https://www.kaggle.com/c/2021-ai-training/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chair', 'rocket', 'fox', 'poppy', 'apple', 'trout', 'palm_tree', 'seal', 'bridge', 'kangaroo', 'aquarium_fish', 'dolphin', 'beetle', 'pickup_truck', 'plain', 'can', 'snake', 'squirrel', 'skunk', 'lizard', 'bicycle', 'bottle', 'caterpillar', 'flatfish', 'shrew', 'lion', 'skyscraper', 'leopard', 'mountain', 'orange', 'porcupine', 'chimpanzee', 'motorcycle', 'hamster', 'otter', 'bee', 'mouse', 'worm', 'mushroom', 'cockroach', 'crocodile', 'bowl', 'willow_tree', 'lobster', 'train', 'road', 'tank', 'rose', 'streetcar', 'camel', 'lawn_mower', 'table', 'oak_tree', 'tiger', 'bear', 'woman', 'pine_tree', 'dinosaur', 'bus', 'bed', 'butterfly', 'man', 'shark', 'sunflower', 'raccoon', 'wardrobe', 'rabbit', 'crab', 'beaver', 'lamp', 'cattle', 'orchid', 'ray', 'elephant', 'clock', 'baby', 'boy', 'castle', 'cup', 'forest', 'possum', 'sweet_pepper', 'telephone', 'maple_tree', 'tulip', 'girl', 'pear', 'television', 'whale', 'spider', 'snail', 'wolf', 'house', 'keyboard', 'couch', 'cloud', 'turtle', 'tractor', 'sea', 'plate']\n"
     ]
    }
   ],
   "source": [
    "data_dir = './2021-ai-training/CIFAR100'\n",
    "classes = os.listdir(data_dir + \"/TRAIN\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  8 03:29:22 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 3090    Off  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 88%   60C    P8    52W / 350W |      2MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 3090    Off  | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 35%   40C    P8    32W / 350W |   9170MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "数据预处理\n",
    "'''\n",
    "\n",
    "method='null'\n",
    "\n",
    "\n",
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            # (x,y)表示方形补丁的中心位置\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "normalize = tt.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
    "train_tfms = tt.Compose([\n",
    "        tt.RandomCrop(32, padding=4),\n",
    "        tt.RandomHorizontalFlip(),\n",
    "        tt.ToTensor(),\n",
    "        normalize,\n",
    "])\n",
    "\n",
    "if method=='cutout':\n",
    "    #train_tfms.append(Cutout(n_holes=1, length=16))\n",
    "    tt.Compose([\n",
    "        tt.RandomCrop(32, padding=4),\n",
    "        tt.RandomHorizontalFlip(),\n",
    "        tt.ToTensor(),\n",
    "        normalize,\n",
    "        Cutout(n_holes=1, length=8),\n",
    "])\n",
    "    \n",
    "valid_tfms = tt.Compose([\n",
    "#         tt.Resize(256),  # transforms.Scale(256)\n",
    "#         tt.CenterCrop(224),\n",
    "        tt.ToTensor(),\n",
    "        normalize,\n",
    "])\n",
    "\n",
    "# 对数据做标准化\n",
    "# 训练集与测试集\n",
    "train_ds = ImageFolder(root=data_dir+\"/TRAIN\",transform=train_tfms)\n",
    "valid_ds = ImageFolder(root=data_dir+\"/TEST\",transform=valid_tfms)\n",
    "\n",
    "# 用pytorh读取数据\n",
    "BATCH_SIZE=128\n",
    "train_dl = DataLoader(train_ds,batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds,batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "#用CGPU读取数据集\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "    \n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "数据增强方法\n",
    "'''\n",
    "def mixup_data(x, y, alpha=1, device=torch.device(\"cuda\")):\n",
    "    \"\"\"Returns mixed inputs, pairs of targets, and lambda\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size)\n",
    "    index = index.to(device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "# def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "#     return lam * criterion(pred, y_a) + (1. - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0, device=torch.device(\"cuda\")):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    rand_index = torch.randperm(x.size()[0]).to(device)\n",
    "    y_a = y\n",
    "    y_b = y[rand_index]\n",
    "    bbx1, bby1, bbx2, bby2 = _rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "    # adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "# def cutmix_criterion(criterion, pred, y_a, y_b, lam):\n",
    "#     return lam * criterion(pred, y_a) + (1. - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "def _rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "DenseNet模型\n",
    "'''\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
    "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self,batch,method):\n",
    "        '''\n",
    "        这里更改方法\n",
    "        '''\n",
    "        if method=='null' or method=='cutout':\n",
    "            images,labels = batch\n",
    "            out = self(images)\n",
    "            loss = F.cross_entropy(out,labels)#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        elif method=='mixup':\n",
    "            images,labels = batch\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(images, labels)\n",
    "            out = self(inputs)\n",
    "            loss = lam * F.cross_entropy(out, targets_a) + (1. - lam) * F.cross_entropy(out, targets_b)\n",
    "        elif method=='cutmix':\n",
    "            images,labels = batch\n",
    "            r = np.random.rand(1)\n",
    "            cutmix_prob=0.5\n",
    "            if r < cutmix_prob:\n",
    "                inputs, targets_a, targets_b, lam = cutmix_data(images, labels)\n",
    "                out = self(inputs)\n",
    "                loss = lam * F.cross_entropy(out, targets_a) + (1. - lam) * F.cross_entropy(out, targets_b)\n",
    "            else:\n",
    "                out = self(images)\n",
    "                loss = F.cross_entropy(out,labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch):\n",
    "        images,labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out,labels)\n",
    "        acc = accuracy(out,labels)\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "        \n",
    "\n",
    "class DenseNet_Cifar(ImageClassificationBase):\n",
    "    def __init__(self, growth_rate=12, block_config=(16, 16, 16),\n",
    "                 num_init_features=24, bn_size=4, drop_rate=0, num_classes=10):\n",
    "\n",
    "        super(DenseNet_Cifar, self).__init__()\n",
    "\n",
    "        # First convolution\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "        ]))\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = _Transition(num_input_features=num_features, num_output_features=num_features // 2)\n",
    "                self.features.add_module('transition%d' % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
    "\n",
    "        # Linear layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # initialize conv and bn parameters\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.avg_pool2d(out, kernel_size=8, stride=1).view(features.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def densenet_BC_cifar(depth, k, **kwargs):\n",
    "    N = (depth - 4) // 6\n",
    "    model = DenseNet_Cifar(growth_rate=k, block_config=[N, N, N], num_init_features=2*k, **kwargs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    if epoch < 75:\n",
    "        lrr = lr\n",
    "    elif epoch < 112:\n",
    "        lrr = lr * 0.1\n",
    "    else:\n",
    "        lrr = lr * 0.01\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lrr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "训练\n",
    "'''\n",
    "import math\n",
    "#调节depth可以调节层数\n",
    "model = densenet_BC_cifar(depth=100, k=12, num_classes=100)\n",
    "model = to_device(model,device)\n",
    "\n",
    "epochs=300\n",
    "lr=0.1\n",
    "momentum=0.9\n",
    "weight_decay=1e-4\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "def Train (epochs,train_dl,valid_dl,model,optimizer,method):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    history = []\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        lrs = []\n",
    "        \n",
    "        for batch in train_dl:\n",
    "            loss = model.training_step(batch,method)#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            train_loss.append(loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lrs.append(get_lr(optimizer))\n",
    "\n",
    "    \n",
    "        result = evaluate(model,valid_dl)\n",
    "        result[\"train_loss\"] = torch.stack(train_loss).mean().item()\n",
    "        result[\"lrs\"] = lrs\n",
    "        \n",
    "        model.epoch_end(epoch,result)\n",
    "        history.append(result)\n",
    "        \n",
    "    return history\n",
    "            \n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model,valid_dl):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in valid_dl]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutmix训练过程：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-208cd64da7c0>:47: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  cut_w = np.int(W * cut_rat)\n",
      "<ipython-input-4-208cd64da7c0>:48: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  cut_h = np.int(H * cut_rat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.10000, train_loss: 4.0810, val_loss: 3.6960, val_acc: 0.1347\n",
      "Epoch [1], last_lr: 0.10000, train_loss: 3.6430, val_loss: 3.4220, val_acc: 0.1820\n",
      "Epoch [2], last_lr: 0.10000, train_loss: 3.3197, val_loss: 2.8246, val_acc: 0.2753\n",
      "Epoch [3], last_lr: 0.10000, train_loss: 3.0035, val_loss: 2.5475, val_acc: 0.3457\n",
      "Epoch [4], last_lr: 0.10000, train_loss: 2.8367, val_loss: 2.3056, val_acc: 0.3899\n",
      "Epoch [5], last_lr: 0.10000, train_loss: 2.6738, val_loss: 2.2769, val_acc: 0.4015\n",
      "Epoch [6], last_lr: 0.10000, train_loss: 2.5114, val_loss: 2.0142, val_acc: 0.4588\n",
      "Epoch [7], last_lr: 0.10000, train_loss: 2.4325, val_loss: 2.0654, val_acc: 0.4493\n",
      "Epoch [8], last_lr: 0.10000, train_loss: 2.3729, val_loss: 1.9683, val_acc: 0.4754\n",
      "Epoch [9], last_lr: 0.10000, train_loss: 2.3655, val_loss: 1.7681, val_acc: 0.5190\n",
      "Epoch [10], last_lr: 0.10000, train_loss: 2.2831, val_loss: 1.7131, val_acc: 0.5204\n",
      "Epoch [11], last_lr: 0.10000, train_loss: 2.2316, val_loss: 1.6681, val_acc: 0.5472\n",
      "Epoch [12], last_lr: 0.10000, train_loss: 2.1422, val_loss: 1.8620, val_acc: 0.5066\n",
      "Epoch [13], last_lr: 0.10000, train_loss: 2.1564, val_loss: 1.6287, val_acc: 0.5511\n",
      "Epoch [14], last_lr: 0.10000, train_loss: 2.0176, val_loss: 1.6009, val_acc: 0.5552\n",
      "Epoch [15], last_lr: 0.10000, train_loss: 2.0407, val_loss: 1.6483, val_acc: 0.5516\n",
      "Epoch [16], last_lr: 0.10000, train_loss: 1.9638, val_loss: 1.7683, val_acc: 0.5416\n",
      "Epoch [17], last_lr: 0.10000, train_loss: 1.9554, val_loss: 1.5895, val_acc: 0.5678\n",
      "Epoch [18], last_lr: 0.10000, train_loss: 1.9724, val_loss: 1.5433, val_acc: 0.5787\n",
      "Epoch [19], last_lr: 0.10000, train_loss: 1.9507, val_loss: 1.5900, val_acc: 0.5699\n",
      "Epoch [20], last_lr: 0.10000, train_loss: 1.8714, val_loss: 1.4374, val_acc: 0.6027\n",
      "Epoch [21], last_lr: 0.10000, train_loss: 1.9041, val_loss: 1.4863, val_acc: 0.5889\n",
      "Epoch [22], last_lr: 0.10000, train_loss: 1.8287, val_loss: 1.5899, val_acc: 0.5650\n",
      "Epoch [23], last_lr: 0.10000, train_loss: 1.8051, val_loss: 1.4508, val_acc: 0.5973\n",
      "Epoch [24], last_lr: 0.10000, train_loss: 1.8143, val_loss: 1.5013, val_acc: 0.5892\n",
      "Epoch [25], last_lr: 0.10000, train_loss: 1.8261, val_loss: 1.4292, val_acc: 0.6042\n",
      "Epoch [26], last_lr: 0.10000, train_loss: 1.7880, val_loss: 1.5848, val_acc: 0.5766\n",
      "Epoch [27], last_lr: 0.10000, train_loss: 1.7817, val_loss: 1.4795, val_acc: 0.5976\n",
      "Epoch [28], last_lr: 0.10000, train_loss: 1.8628, val_loss: 1.4127, val_acc: 0.6025\n",
      "Epoch [29], last_lr: 0.10000, train_loss: 1.7953, val_loss: 1.5348, val_acc: 0.5898\n",
      "Epoch [30], last_lr: 0.10000, train_loss: 1.6695, val_loss: 1.4663, val_acc: 0.6017\n",
      "Epoch [31], last_lr: 0.10000, train_loss: 1.8181, val_loss: 1.3330, val_acc: 0.6325\n",
      "Epoch [32], last_lr: 0.10000, train_loss: 1.6767, val_loss: 1.3559, val_acc: 0.6294\n",
      "Epoch [33], last_lr: 0.10000, train_loss: 1.6458, val_loss: 1.3380, val_acc: 0.6279\n",
      "Epoch [34], last_lr: 0.10000, train_loss: 1.6689, val_loss: 1.4277, val_acc: 0.6108\n",
      "Epoch [35], last_lr: 0.10000, train_loss: 1.7007, val_loss: 1.3443, val_acc: 0.6264\n",
      "Epoch [36], last_lr: 0.10000, train_loss: 1.6448, val_loss: 1.2787, val_acc: 0.6451\n",
      "Epoch [37], last_lr: 0.10000, train_loss: 1.6680, val_loss: 1.3594, val_acc: 0.6268\n",
      "Epoch [38], last_lr: 0.10000, train_loss: 1.5622, val_loss: 1.3831, val_acc: 0.6259\n",
      "Epoch [39], last_lr: 0.10000, train_loss: 1.7733, val_loss: 1.2985, val_acc: 0.6449\n",
      "Epoch [40], last_lr: 0.10000, train_loss: 1.6584, val_loss: 1.3052, val_acc: 0.6440\n",
      "Epoch [41], last_lr: 0.10000, train_loss: 1.7044, val_loss: 1.3078, val_acc: 0.6428\n",
      "Epoch [42], last_lr: 0.10000, train_loss: 1.7136, val_loss: 1.2947, val_acc: 0.6422\n",
      "Epoch [43], last_lr: 0.10000, train_loss: 1.6709, val_loss: 1.3359, val_acc: 0.6321\n",
      "Epoch [44], last_lr: 0.10000, train_loss: 1.5504, val_loss: 1.3625, val_acc: 0.6334\n",
      "Epoch [45], last_lr: 0.10000, train_loss: 1.6838, val_loss: 1.3048, val_acc: 0.6449\n",
      "Epoch [46], last_lr: 0.10000, train_loss: 1.6161, val_loss: 1.2817, val_acc: 0.6434\n",
      "Epoch [47], last_lr: 0.10000, train_loss: 1.5894, val_loss: 1.2651, val_acc: 0.6478\n",
      "Epoch [48], last_lr: 0.10000, train_loss: 1.5794, val_loss: 1.3069, val_acc: 0.6475\n",
      "Epoch [49], last_lr: 0.10000, train_loss: 1.6393, val_loss: 1.3653, val_acc: 0.6264\n",
      "Epoch [50], last_lr: 0.10000, train_loss: 1.5898, val_loss: 1.3147, val_acc: 0.6381\n",
      "Epoch [51], last_lr: 0.10000, train_loss: 1.6268, val_loss: 1.2288, val_acc: 0.6588\n",
      "Epoch [52], last_lr: 0.10000, train_loss: 1.6485, val_loss: 1.2424, val_acc: 0.6563\n",
      "Epoch [53], last_lr: 0.10000, train_loss: 1.5925, val_loss: 1.4167, val_acc: 0.6247\n",
      "Epoch [54], last_lr: 0.10000, train_loss: 1.6238, val_loss: 1.1888, val_acc: 0.6649\n",
      "Epoch [55], last_lr: 0.10000, train_loss: 1.5360, val_loss: 1.2803, val_acc: 0.6478\n",
      "Epoch [56], last_lr: 0.10000, train_loss: 1.5786, val_loss: 1.2620, val_acc: 0.6561\n",
      "Epoch [57], last_lr: 0.10000, train_loss: 1.5070, val_loss: 1.2681, val_acc: 0.6529\n",
      "Epoch [58], last_lr: 0.10000, train_loss: 1.4879, val_loss: 1.2902, val_acc: 0.6492\n",
      "Epoch [59], last_lr: 0.10000, train_loss: 1.5511, val_loss: 1.2683, val_acc: 0.6473\n",
      "Epoch [60], last_lr: 0.10000, train_loss: 1.5465, val_loss: 1.2923, val_acc: 0.6473\n",
      "Epoch [61], last_lr: 0.10000, train_loss: 1.5799, val_loss: 1.2816, val_acc: 0.6520\n",
      "Epoch [62], last_lr: 0.10000, train_loss: 1.5582, val_loss: 1.2415, val_acc: 0.6584\n",
      "Epoch [63], last_lr: 0.10000, train_loss: 1.5088, val_loss: 1.2819, val_acc: 0.6440\n",
      "Epoch [64], last_lr: 0.10000, train_loss: 1.4762, val_loss: 1.1714, val_acc: 0.6755\n",
      "Epoch [65], last_lr: 0.10000, train_loss: 1.4644, val_loss: 1.2119, val_acc: 0.6669\n",
      "Epoch [66], last_lr: 0.10000, train_loss: 1.5624, val_loss: 1.2953, val_acc: 0.6454\n",
      "Epoch [67], last_lr: 0.10000, train_loss: 1.4910, val_loss: 1.1585, val_acc: 0.6816\n",
      "Epoch [68], last_lr: 0.10000, train_loss: 1.4695, val_loss: 1.4438, val_acc: 0.6255\n",
      "Epoch [69], last_lr: 0.10000, train_loss: 1.5248, val_loss: 1.2726, val_acc: 0.6466\n",
      "Epoch [70], last_lr: 0.10000, train_loss: 1.4625, val_loss: 1.2120, val_acc: 0.6680\n",
      "Epoch [71], last_lr: 0.10000, train_loss: 1.5127, val_loss: 1.2731, val_acc: 0.6502\n",
      "Epoch [72], last_lr: 0.10000, train_loss: 1.4442, val_loss: 1.1509, val_acc: 0.6829\n",
      "Epoch [73], last_lr: 0.10000, train_loss: 1.4858, val_loss: 1.2080, val_acc: 0.6667\n",
      "Epoch [74], last_lr: 0.10000, train_loss: 1.4862, val_loss: 1.2062, val_acc: 0.6691\n",
      "Epoch [75], last_lr: 0.01000, train_loss: 1.2345, val_loss: 0.8416, val_acc: 0.7592\n",
      "Epoch [76], last_lr: 0.01000, train_loss: 1.2362, val_loss: 0.8267, val_acc: 0.7646\n",
      "Epoch [77], last_lr: 0.01000, train_loss: 1.1645, val_loss: 0.8173, val_acc: 0.7669\n",
      "Epoch [78], last_lr: 0.01000, train_loss: 1.1178, val_loss: 0.7987, val_acc: 0.7691\n",
      "Epoch [79], last_lr: 0.01000, train_loss: 1.1478, val_loss: 0.8143, val_acc: 0.7707\n",
      "Epoch [80], last_lr: 0.01000, train_loss: 1.0595, val_loss: 0.8186, val_acc: 0.7697\n",
      "Epoch [81], last_lr: 0.01000, train_loss: 1.0753, val_loss: 0.8061, val_acc: 0.7718\n",
      "Epoch [82], last_lr: 0.01000, train_loss: 1.2667, val_loss: 0.8095, val_acc: 0.7718\n",
      "Epoch [83], last_lr: 0.01000, train_loss: 1.0940, val_loss: 0.8173, val_acc: 0.7727\n",
      "Epoch [84], last_lr: 0.01000, train_loss: 1.0215, val_loss: 0.8202, val_acc: 0.7698\n",
      "Epoch [85], last_lr: 0.01000, train_loss: 1.0682, val_loss: 0.8100, val_acc: 0.7724\n",
      "Epoch [86], last_lr: 0.01000, train_loss: 1.0009, val_loss: 0.8019, val_acc: 0.7731\n",
      "Epoch [87], last_lr: 0.01000, train_loss: 1.0877, val_loss: 0.8125, val_acc: 0.7738\n",
      "Epoch [88], last_lr: 0.01000, train_loss: 1.0368, val_loss: 0.8128, val_acc: 0.7741\n",
      "Epoch [89], last_lr: 0.01000, train_loss: 1.0230, val_loss: 0.8253, val_acc: 0.7686\n",
      "Epoch [90], last_lr: 0.01000, train_loss: 1.0314, val_loss: 0.8292, val_acc: 0.7681\n",
      "Epoch [91], last_lr: 0.01000, train_loss: 0.9140, val_loss: 0.8226, val_acc: 0.7715\n",
      "Epoch [92], last_lr: 0.01000, train_loss: 1.0342, val_loss: 0.8465, val_acc: 0.7675\n",
      "Epoch [93], last_lr: 0.01000, train_loss: 0.9918, val_loss: 0.8245, val_acc: 0.7695\n",
      "Epoch [94], last_lr: 0.01000, train_loss: 1.0779, val_loss: 0.8264, val_acc: 0.7684\n",
      "Epoch [95], last_lr: 0.01000, train_loss: 0.9950, val_loss: 0.8196, val_acc: 0.7708\n",
      "Epoch [96], last_lr: 0.01000, train_loss: 0.9684, val_loss: 0.8200, val_acc: 0.7682\n",
      "Epoch [97], last_lr: 0.01000, train_loss: 1.0562, val_loss: 0.8303, val_acc: 0.7670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98], last_lr: 0.01000, train_loss: 1.0995, val_loss: 0.8297, val_acc: 0.7722\n",
      "Epoch [99], last_lr: 0.01000, train_loss: 0.9669, val_loss: 0.8589, val_acc: 0.7666\n",
      "Epoch [100], last_lr: 0.01000, train_loss: 0.8757, val_loss: 0.8386, val_acc: 0.7644\n",
      "Epoch [101], last_lr: 0.01000, train_loss: 1.1605, val_loss: 0.8420, val_acc: 0.7657\n",
      "Epoch [102], last_lr: 0.01000, train_loss: 1.0024, val_loss: 0.8420, val_acc: 0.7670\n",
      "Epoch [103], last_lr: 0.01000, train_loss: 1.0100, val_loss: 0.8472, val_acc: 0.7673\n",
      "Epoch [104], last_lr: 0.01000, train_loss: 0.8896, val_loss: 0.8535, val_acc: 0.7631\n",
      "Epoch [105], last_lr: 0.01000, train_loss: 1.0134, val_loss: 0.8556, val_acc: 0.7661\n",
      "Epoch [106], last_lr: 0.01000, train_loss: 0.9622, val_loss: 0.8482, val_acc: 0.7674\n",
      "Epoch [107], last_lr: 0.01000, train_loss: 0.8157, val_loss: 0.8522, val_acc: 0.7693\n",
      "Epoch [108], last_lr: 0.01000, train_loss: 0.9520, val_loss: 0.8512, val_acc: 0.7640\n",
      "Epoch [109], last_lr: 0.01000, train_loss: 0.9793, val_loss: 0.8483, val_acc: 0.7689\n",
      "Epoch [110], last_lr: 0.01000, train_loss: 1.0368, val_loss: 0.8450, val_acc: 0.7680\n",
      "Epoch [111], last_lr: 0.01000, train_loss: 1.0309, val_loss: 0.8604, val_acc: 0.7636\n",
      "Epoch [112], last_lr: 0.00100, train_loss: 0.8896, val_loss: 0.8291, val_acc: 0.7677\n",
      "Epoch [113], last_lr: 0.00100, train_loss: 0.9163, val_loss: 0.8185, val_acc: 0.7716\n",
      "Epoch [114], last_lr: 0.00100, train_loss: 0.9160, val_loss: 0.8194, val_acc: 0.7721\n",
      "Epoch [115], last_lr: 0.00100, train_loss: 0.9620, val_loss: 0.8211, val_acc: 0.7721\n",
      "Epoch [116], last_lr: 0.00100, train_loss: 0.9538, val_loss: 0.8286, val_acc: 0.7701\n",
      "Epoch [117], last_lr: 0.00100, train_loss: 0.9296, val_loss: 0.8217, val_acc: 0.7716\n",
      "Epoch [118], last_lr: 0.00100, train_loss: 0.8854, val_loss: 0.8185, val_acc: 0.7738\n",
      "Epoch [119], last_lr: 0.00100, train_loss: 0.8907, val_loss: 0.8228, val_acc: 0.7711\n",
      "Epoch [120], last_lr: 0.00100, train_loss: 0.8883, val_loss: 0.8223, val_acc: 0.7716\n",
      "Epoch [121], last_lr: 0.00100, train_loss: 1.0700, val_loss: 0.8169, val_acc: 0.7707\n",
      "Epoch [122], last_lr: 0.00100, train_loss: 0.8291, val_loss: 0.8228, val_acc: 0.7734\n",
      "Epoch [123], last_lr: 0.00100, train_loss: 0.9266, val_loss: 0.8316, val_acc: 0.7710\n",
      "Epoch [124], last_lr: 0.00100, train_loss: 0.9465, val_loss: 0.8215, val_acc: 0.7719\n",
      "Epoch [125], last_lr: 0.00100, train_loss: 0.9214, val_loss: 0.8243, val_acc: 0.7721\n",
      "Epoch [126], last_lr: 0.00100, train_loss: 0.8948, val_loss: 0.8204, val_acc: 0.7710\n",
      "Epoch [127], last_lr: 0.00100, train_loss: 0.9659, val_loss: 0.8198, val_acc: 0.7705\n",
      "Epoch [128], last_lr: 0.00100, train_loss: 0.8266, val_loss: 0.8260, val_acc: 0.7729\n",
      "Epoch [129], last_lr: 0.00100, train_loss: 0.9640, val_loss: 0.8308, val_acc: 0.7726\n",
      "Epoch [130], last_lr: 0.00100, train_loss: 0.9492, val_loss: 0.8183, val_acc: 0.7736\n",
      "Epoch [131], last_lr: 0.00100, train_loss: 0.9062, val_loss: 0.8189, val_acc: 0.7734\n",
      "Epoch [132], last_lr: 0.00100, train_loss: 0.9260, val_loss: 0.8217, val_acc: 0.7706\n",
      "Epoch [133], last_lr: 0.00100, train_loss: 0.9220, val_loss: 0.8231, val_acc: 0.7714\n",
      "Epoch [134], last_lr: 0.00100, train_loss: 0.9207, val_loss: 0.8253, val_acc: 0.7723\n",
      "Epoch [135], last_lr: 0.00100, train_loss: 0.9293, val_loss: 0.8255, val_acc: 0.7717\n",
      "Epoch [136], last_lr: 0.00100, train_loss: 0.9157, val_loss: 0.8209, val_acc: 0.7706\n",
      "Epoch [137], last_lr: 0.00100, train_loss: 0.9538, val_loss: 0.8207, val_acc: 0.7694\n",
      "Epoch [138], last_lr: 0.00100, train_loss: 0.8532, val_loss: 0.8245, val_acc: 0.7708\n",
      "Epoch [139], last_lr: 0.00100, train_loss: 0.9017, val_loss: 0.8280, val_acc: 0.7707\n",
      "Epoch [140], last_lr: 0.00100, train_loss: 1.0643, val_loss: 0.8379, val_acc: 0.7698\n",
      "Epoch [141], last_lr: 0.00100, train_loss: 0.9102, val_loss: 0.8276, val_acc: 0.7701\n",
      "Epoch [142], last_lr: 0.00100, train_loss: 0.9066, val_loss: 0.8242, val_acc: 0.7694\n",
      "Epoch [143], last_lr: 0.00100, train_loss: 0.9019, val_loss: 0.8228, val_acc: 0.7703\n",
      "Epoch [144], last_lr: 0.00100, train_loss: 0.9047, val_loss: 0.8270, val_acc: 0.7709\n",
      "Epoch [145], last_lr: 0.00100, train_loss: 0.8421, val_loss: 0.8284, val_acc: 0.7714\n",
      "Epoch [146], last_lr: 0.00100, train_loss: 0.9561, val_loss: 0.8270, val_acc: 0.7728\n",
      "Epoch [147], last_lr: 0.00100, train_loss: 0.9844, val_loss: 0.8222, val_acc: 0.7727\n",
      "Epoch [148], last_lr: 0.00100, train_loss: 0.9750, val_loss: 0.8222, val_acc: 0.7709\n",
      "Epoch [149], last_lr: 0.00100, train_loss: 0.9510, val_loss: 0.8229, val_acc: 0.7716\n",
      "Epoch [150], last_lr: 0.00100, train_loss: 0.9630, val_loss: 0.8223, val_acc: 0.7735\n",
      "Epoch [151], last_lr: 0.00100, train_loss: 0.9945, val_loss: 0.8212, val_acc: 0.7739\n",
      "Epoch [152], last_lr: 0.00100, train_loss: 0.9713, val_loss: 0.8250, val_acc: 0.7695\n",
      "Epoch [153], last_lr: 0.00100, train_loss: 0.9144, val_loss: 0.8449, val_acc: 0.7694\n",
      "Epoch [154], last_lr: 0.00100, train_loss: 0.8873, val_loss: 0.8237, val_acc: 0.7698\n",
      "Epoch [155], last_lr: 0.00100, train_loss: 0.9579, val_loss: 0.8349, val_acc: 0.7725\n",
      "Epoch [156], last_lr: 0.00100, train_loss: 0.9171, val_loss: 0.8238, val_acc: 0.7703\n",
      "Epoch [157], last_lr: 0.00100, train_loss: 0.8631, val_loss: 0.8367, val_acc: 0.7704\n",
      "Epoch [158], last_lr: 0.00100, train_loss: 0.8810, val_loss: 0.8289, val_acc: 0.7722\n",
      "Epoch [159], last_lr: 0.00100, train_loss: 0.9531, val_loss: 0.8203, val_acc: 0.7726\n",
      "Epoch [160], last_lr: 0.00100, train_loss: 0.8898, val_loss: 0.8283, val_acc: 0.7705\n",
      "Epoch [161], last_lr: 0.00100, train_loss: 0.9093, val_loss: 0.8269, val_acc: 0.7711\n",
      "Epoch [162], last_lr: 0.00100, train_loss: 0.9749, val_loss: 0.8236, val_acc: 0.7707\n",
      "Epoch [163], last_lr: 0.00100, train_loss: 0.8503, val_loss: 0.8330, val_acc: 0.7709\n",
      "Epoch [164], last_lr: 0.00100, train_loss: 0.8839, val_loss: 0.8273, val_acc: 0.7713\n",
      "Epoch [165], last_lr: 0.00100, train_loss: 0.8308, val_loss: 0.8269, val_acc: 0.7701\n",
      "Epoch [166], last_lr: 0.00100, train_loss: 0.9390, val_loss: 0.8283, val_acc: 0.7721\n",
      "Epoch [167], last_lr: 0.00100, train_loss: 0.9168, val_loss: 0.8281, val_acc: 0.7699\n",
      "Epoch [168], last_lr: 0.00100, train_loss: 0.9318, val_loss: 0.8327, val_acc: 0.7696\n",
      "Epoch [169], last_lr: 0.00100, train_loss: 1.0056, val_loss: 0.8306, val_acc: 0.7704\n",
      "Epoch [170], last_lr: 0.00100, train_loss: 0.9330, val_loss: 0.8307, val_acc: 0.7721\n",
      "Epoch [171], last_lr: 0.00100, train_loss: 0.8739, val_loss: 0.8262, val_acc: 0.7718\n",
      "Epoch [172], last_lr: 0.00100, train_loss: 0.8595, val_loss: 0.8296, val_acc: 0.7694\n",
      "Epoch [173], last_lr: 0.00100, train_loss: 0.8839, val_loss: 0.8300, val_acc: 0.7707\n",
      "Epoch [174], last_lr: 0.00100, train_loss: 0.9930, val_loss: 0.8346, val_acc: 0.7684\n",
      "Epoch [175], last_lr: 0.00100, train_loss: 0.9097, val_loss: 0.8269, val_acc: 0.7700\n",
      "Epoch [176], last_lr: 0.00100, train_loss: 1.0421, val_loss: 0.8342, val_acc: 0.7709\n",
      "Epoch [177], last_lr: 0.00100, train_loss: 0.9451, val_loss: 0.8267, val_acc: 0.7738\n",
      "Epoch [178], last_lr: 0.00100, train_loss: 0.8730, val_loss: 0.8300, val_acc: 0.7722\n",
      "Epoch [179], last_lr: 0.00100, train_loss: 0.9027, val_loss: 0.8291, val_acc: 0.7733\n",
      "Epoch [180], last_lr: 0.00100, train_loss: 0.8776, val_loss: 0.8546, val_acc: 0.7711\n",
      "Epoch [181], last_lr: 0.00100, train_loss: 0.8993, val_loss: 0.8533, val_acc: 0.7720\n",
      "Epoch [182], last_lr: 0.00100, train_loss: 0.8888, val_loss: 0.8303, val_acc: 0.7724\n",
      "Epoch [183], last_lr: 0.00100, train_loss: 0.9128, val_loss: 0.8350, val_acc: 0.7735\n",
      "Epoch [184], last_lr: 0.00100, train_loss: 0.8743, val_loss: 0.8319, val_acc: 0.7705\n",
      "Epoch [185], last_lr: 0.00100, train_loss: 0.9013, val_loss: 0.8341, val_acc: 0.7725\n",
      "Epoch [186], last_lr: 0.00100, train_loss: 0.8779, val_loss: 0.8729, val_acc: 0.7708\n",
      "Epoch [187], last_lr: 0.00100, train_loss: 0.9103, val_loss: 0.8300, val_acc: 0.7744\n",
      "Epoch [188], last_lr: 0.00100, train_loss: 0.8873, val_loss: 0.8283, val_acc: 0.7708\n",
      "Epoch [189], last_lr: 0.00100, train_loss: 0.8784, val_loss: 0.8288, val_acc: 0.7713\n",
      "Epoch [190], last_lr: 0.00100, train_loss: 0.9636, val_loss: 0.8371, val_acc: 0.7704\n",
      "Epoch [191], last_lr: 0.00100, train_loss: 0.9327, val_loss: 0.8307, val_acc: 0.7694\n",
      "Epoch [192], last_lr: 0.00100, train_loss: 0.8950, val_loss: 0.8406, val_acc: 0.7723\n",
      "Epoch [193], last_lr: 0.00100, train_loss: 0.9479, val_loss: 0.8332, val_acc: 0.7741\n",
      "Epoch [194], last_lr: 0.00100, train_loss: 0.8665, val_loss: 0.8393, val_acc: 0.7752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [195], last_lr: 0.00100, train_loss: 0.9091, val_loss: 0.8298, val_acc: 0.7723\n",
      "Epoch [196], last_lr: 0.00100, train_loss: 0.9111, val_loss: 0.8374, val_acc: 0.7682\n",
      "Epoch [197], last_lr: 0.00100, train_loss: 0.9430, val_loss: 0.8380, val_acc: 0.7714\n",
      "Epoch [198], last_lr: 0.00100, train_loss: 0.9401, val_loss: 0.8385, val_acc: 0.7697\n",
      "Epoch [199], last_lr: 0.00100, train_loss: 0.8683, val_loss: 0.8356, val_acc: 0.7701\n",
      "Epoch [200], last_lr: 0.00100, train_loss: 0.8889, val_loss: 0.8337, val_acc: 0.7738\n",
      "Epoch [201], last_lr: 0.00100, train_loss: 0.7897, val_loss: 0.8328, val_acc: 0.7714\n",
      "Epoch [202], last_lr: 0.00100, train_loss: 0.8195, val_loss: 0.8622, val_acc: 0.7710\n",
      "Epoch [203], last_lr: 0.00100, train_loss: 0.8793, val_loss: 0.8337, val_acc: 0.7726\n",
      "Epoch [204], last_lr: 0.00100, train_loss: 0.9381, val_loss: 0.8404, val_acc: 0.7715\n",
      "Epoch [205], last_lr: 0.00100, train_loss: 0.8437, val_loss: 0.8387, val_acc: 0.7711\n",
      "Epoch [206], last_lr: 0.00100, train_loss: 0.9157, val_loss: 0.8366, val_acc: 0.7707\n",
      "Epoch [207], last_lr: 0.00100, train_loss: 0.8781, val_loss: 0.8386, val_acc: 0.7711\n",
      "Epoch [208], last_lr: 0.00100, train_loss: 0.8757, val_loss: 0.8366, val_acc: 0.7724\n",
      "Epoch [209], last_lr: 0.00100, train_loss: 0.9057, val_loss: 0.8375, val_acc: 0.7700\n",
      "Epoch [210], last_lr: 0.00100, train_loss: 0.8994, val_loss: 0.8373, val_acc: 0.7715\n",
      "Epoch [211], last_lr: 0.00100, train_loss: 0.8930, val_loss: 0.8453, val_acc: 0.7715\n",
      "Epoch [212], last_lr: 0.00100, train_loss: 0.8917, val_loss: 0.8517, val_acc: 0.7721\n",
      "Epoch [213], last_lr: 0.00100, train_loss: 0.8901, val_loss: 0.8350, val_acc: 0.7705\n",
      "Epoch [214], last_lr: 0.00100, train_loss: 0.9168, val_loss: 0.8368, val_acc: 0.7694\n",
      "Epoch [215], last_lr: 0.00100, train_loss: 0.9378, val_loss: 0.8373, val_acc: 0.7713\n",
      "Epoch [216], last_lr: 0.00100, train_loss: 0.8774, val_loss: 0.8423, val_acc: 0.7725\n",
      "Epoch [217], last_lr: 0.00100, train_loss: 0.8878, val_loss: 0.8472, val_acc: 0.7678\n",
      "Epoch [218], last_lr: 0.00100, train_loss: 0.9037, val_loss: 0.8420, val_acc: 0.7698\n",
      "Epoch [219], last_lr: 0.00100, train_loss: 0.9613, val_loss: 0.8442, val_acc: 0.7716\n",
      "Epoch [220], last_lr: 0.00100, train_loss: 0.9051, val_loss: 0.8377, val_acc: 0.7731\n",
      "Epoch [221], last_lr: 0.00100, train_loss: 0.8671, val_loss: 0.8471, val_acc: 0.7719\n",
      "Epoch [222], last_lr: 0.00100, train_loss: 0.7901, val_loss: 0.8366, val_acc: 0.7722\n",
      "Epoch [223], last_lr: 0.00100, train_loss: 0.8997, val_loss: 0.8348, val_acc: 0.7700\n",
      "Epoch [224], last_lr: 0.00100, train_loss: 0.8652, val_loss: 0.8408, val_acc: 0.7720\n",
      "Epoch [225], last_lr: 0.00100, train_loss: 0.8368, val_loss: 0.8760, val_acc: 0.7726\n",
      "Epoch [226], last_lr: 0.00100, train_loss: 0.8608, val_loss: 0.8410, val_acc: 0.7727\n",
      "Epoch [227], last_lr: 0.00100, train_loss: 0.7417, val_loss: 0.8383, val_acc: 0.7709\n",
      "Epoch [228], last_lr: 0.00100, train_loss: 0.9471, val_loss: 0.8425, val_acc: 0.7704\n",
      "Epoch [229], last_lr: 0.00100, train_loss: 0.8622, val_loss: 0.8359, val_acc: 0.7718\n",
      "Epoch [230], last_lr: 0.00100, train_loss: 0.8634, val_loss: 0.8396, val_acc: 0.7720\n",
      "Epoch [231], last_lr: 0.00100, train_loss: 0.8448, val_loss: 0.8495, val_acc: 0.7713\n",
      "Epoch [232], last_lr: 0.00100, train_loss: 0.9667, val_loss: 0.8386, val_acc: 0.7708\n",
      "Epoch [233], last_lr: 0.00100, train_loss: 0.9236, val_loss: 0.8455, val_acc: 0.7727\n",
      "Epoch [234], last_lr: 0.00100, train_loss: 0.8928, val_loss: 0.8424, val_acc: 0.7723\n",
      "Epoch [235], last_lr: 0.00100, train_loss: 0.8769, val_loss: 0.8492, val_acc: 0.7687\n",
      "Epoch [236], last_lr: 0.00100, train_loss: 0.8810, val_loss: 0.8375, val_acc: 0.7710\n",
      "Epoch [237], last_lr: 0.00100, train_loss: 0.9861, val_loss: 0.8395, val_acc: 0.7704\n",
      "Epoch [238], last_lr: 0.00100, train_loss: 0.9128, val_loss: 0.8417, val_acc: 0.7724\n",
      "Epoch [239], last_lr: 0.00100, train_loss: 0.8663, val_loss: 0.8398, val_acc: 0.7728\n",
      "Epoch [240], last_lr: 0.00100, train_loss: 0.7608, val_loss: 0.8682, val_acc: 0.7715\n",
      "Epoch [241], last_lr: 0.00100, train_loss: 0.9205, val_loss: 0.8379, val_acc: 0.7723\n",
      "Epoch [242], last_lr: 0.00100, train_loss: 0.8850, val_loss: 0.8360, val_acc: 0.7712\n",
      "Epoch [243], last_lr: 0.00100, train_loss: 0.8911, val_loss: 0.8527, val_acc: 0.7709\n",
      "Epoch [244], last_lr: 0.00100, train_loss: 0.8089, val_loss: 0.8391, val_acc: 0.7716\n",
      "Epoch [245], last_lr: 0.00100, train_loss: 0.8906, val_loss: 0.8378, val_acc: 0.7739\n",
      "Epoch [246], last_lr: 0.00100, train_loss: 0.8573, val_loss: 0.8393, val_acc: 0.7726\n",
      "Epoch [247], last_lr: 0.00100, train_loss: 0.8350, val_loss: 0.8396, val_acc: 0.7728\n",
      "Epoch [248], last_lr: 0.00100, train_loss: 0.8536, val_loss: 0.8366, val_acc: 0.7713\n",
      "Epoch [249], last_lr: 0.00100, train_loss: 0.8401, val_loss: 0.8709, val_acc: 0.7741\n",
      "Epoch [250], last_lr: 0.00100, train_loss: 0.8501, val_loss: 0.8460, val_acc: 0.7715\n",
      "Epoch [251], last_lr: 0.00100, train_loss: 0.8592, val_loss: 0.8364, val_acc: 0.7743\n",
      "Epoch [252], last_lr: 0.00100, train_loss: 0.8975, val_loss: 0.8363, val_acc: 0.7737\n",
      "Epoch [253], last_lr: 0.00100, train_loss: 0.8437, val_loss: 0.8372, val_acc: 0.7726\n",
      "Epoch [254], last_lr: 0.00100, train_loss: 0.9058, val_loss: 0.8403, val_acc: 0.7709\n",
      "Epoch [255], last_lr: 0.00100, train_loss: 0.8374, val_loss: 0.8415, val_acc: 0.7726\n",
      "Epoch [256], last_lr: 0.00100, train_loss: 0.9496, val_loss: 0.8485, val_acc: 0.7711\n",
      "Epoch [257], last_lr: 0.00100, train_loss: 0.7746, val_loss: 0.8639, val_acc: 0.7729\n",
      "Epoch [258], last_lr: 0.00100, train_loss: 0.8920, val_loss: 0.8380, val_acc: 0.7702\n",
      "Epoch [259], last_lr: 0.00100, train_loss: 0.8556, val_loss: 0.8388, val_acc: 0.7713\n",
      "Epoch [260], last_lr: 0.00100, train_loss: 0.9134, val_loss: 0.8493, val_acc: 0.7725\n",
      "Epoch [261], last_lr: 0.00100, train_loss: 0.8884, val_loss: 0.8378, val_acc: 0.7712\n",
      "Epoch [262], last_lr: 0.00100, train_loss: 0.9029, val_loss: 0.8432, val_acc: 0.7700\n",
      "Epoch [263], last_lr: 0.00100, train_loss: 0.9140, val_loss: 0.8385, val_acc: 0.7720\n",
      "Epoch [264], last_lr: 0.00100, train_loss: 0.9282, val_loss: 0.8334, val_acc: 0.7721\n",
      "Epoch [265], last_lr: 0.00100, train_loss: 0.9017, val_loss: 0.8367, val_acc: 0.7737\n",
      "Epoch [266], last_lr: 0.00100, train_loss: 0.9062, val_loss: 0.8345, val_acc: 0.7714\n",
      "Epoch [267], last_lr: 0.00100, train_loss: 0.8883, val_loss: 0.8651, val_acc: 0.7709\n",
      "Epoch [268], last_lr: 0.00100, train_loss: 0.8143, val_loss: 0.8484, val_acc: 0.7723\n",
      "Epoch [269], last_lr: 0.00100, train_loss: 0.7899, val_loss: 0.8422, val_acc: 0.7716\n",
      "Epoch [270], last_lr: 0.00100, train_loss: 0.8695, val_loss: 0.8496, val_acc: 0.7692\n",
      "Epoch [271], last_lr: 0.00100, train_loss: 0.9737, val_loss: 0.8422, val_acc: 0.7714\n",
      "Epoch [272], last_lr: 0.00100, train_loss: 0.8727, val_loss: 0.8496, val_acc: 0.7703\n",
      "Epoch [273], last_lr: 0.00100, train_loss: 0.8855, val_loss: 0.8383, val_acc: 0.7715\n",
      "Epoch [274], last_lr: 0.00100, train_loss: 0.8529, val_loss: 0.8537, val_acc: 0.7714\n",
      "Epoch [275], last_lr: 0.00100, train_loss: 0.9521, val_loss: 0.8457, val_acc: 0.7736\n",
      "Epoch [276], last_lr: 0.00100, train_loss: 0.8424, val_loss: 0.8485, val_acc: 0.7712\n",
      "Epoch [277], last_lr: 0.00100, train_loss: 0.8376, val_loss: 0.8393, val_acc: 0.7731\n",
      "Epoch [278], last_lr: 0.00100, train_loss: 0.8167, val_loss: 0.8480, val_acc: 0.7735\n",
      "Epoch [279], last_lr: 0.00100, train_loss: 0.8864, val_loss: 0.8452, val_acc: 0.7701\n",
      "Epoch [280], last_lr: 0.00100, train_loss: 0.8584, val_loss: 0.8563, val_acc: 0.7679\n",
      "Epoch [281], last_lr: 0.00100, train_loss: 0.8893, val_loss: 0.8609, val_acc: 0.7722\n",
      "Epoch [282], last_lr: 0.00100, train_loss: 0.8403, val_loss: 0.8427, val_acc: 0.7708\n",
      "Epoch [283], last_lr: 0.00100, train_loss: 0.8350, val_loss: 0.8403, val_acc: 0.7700\n",
      "Epoch [284], last_lr: 0.00100, train_loss: 0.8615, val_loss: 0.8400, val_acc: 0.7739\n",
      "Epoch [285], last_lr: 0.00100, train_loss: 0.8643, val_loss: 0.8569, val_acc: 0.7702\n",
      "Epoch [286], last_lr: 0.00100, train_loss: 0.9309, val_loss: 0.8435, val_acc: 0.7711\n",
      "Epoch [287], last_lr: 0.00100, train_loss: 1.0008, val_loss: 0.8430, val_acc: 0.7694\n",
      "Epoch [288], last_lr: 0.00100, train_loss: 0.9184, val_loss: 0.8380, val_acc: 0.7732\n",
      "Epoch [289], last_lr: 0.00100, train_loss: 0.8293, val_loss: 0.8468, val_acc: 0.7731\n",
      "Epoch [290], last_lr: 0.00100, train_loss: 0.9155, val_loss: 0.8487, val_acc: 0.7699\n",
      "Epoch [291], last_lr: 0.00100, train_loss: 0.9142, val_loss: 0.8596, val_acc: 0.7704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [292], last_lr: 0.00100, train_loss: 0.9229, val_loss: 0.8458, val_acc: 0.7741\n",
      "Epoch [293], last_lr: 0.00100, train_loss: 0.9365, val_loss: 0.8618, val_acc: 0.7716\n",
      "Epoch [294], last_lr: 0.00100, train_loss: 0.9016, val_loss: 0.8467, val_acc: 0.7721\n",
      "Epoch [295], last_lr: 0.00100, train_loss: 0.8636, val_loss: 0.8453, val_acc: 0.7714\n",
      "Epoch [296], last_lr: 0.00100, train_loss: 0.8969, val_loss: 0.8595, val_acc: 0.7717\n",
      "Epoch [297], last_lr: 0.00100, train_loss: 0.8272, val_loss: 0.8445, val_acc: 0.7735\n",
      "Epoch [298], last_lr: 0.00100, train_loss: 0.8873, val_loss: 0.8400, val_acc: 0.7735\n",
      "Epoch [299], last_lr: 0.00100, train_loss: 0.8044, val_loss: 0.8644, val_acc: 0.7728\n"
     ]
    }
   ],
   "source": [
    "print('cutmix训练过程：')\n",
    "history_cutmix = []\n",
    "history_cutmix += Train(epochs=epochs,train_dl=train_dl,valid_dl=valid_dl,model=model,optimizer=optimizer,method='cutmix')\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(),'model_cutmix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot([x.get(\"train_loss\") for x in history], \"-bx\")\n",
    "    plt.plot([x[\"val_loss\"] for x in history],\"-rx\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend([\"train loss\",\"test loss\"])\n",
    "    plt.title('CutMix Loss')\n",
    "    plt.show()\n",
    "\n",
    "def plot_testAcc(history):\n",
    "    plt.plot([x.get(\"val_acc\") for x in history], \"-bx\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"acc\")\n",
    "    plt.legend([\"test Acc\"])\n",
    "    plt.title('CutMix Test Acc')\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history_cutmix)\n",
    "plot_testAcc(history_cutmix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
